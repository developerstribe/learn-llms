# Learn LLMs - fast!

Are you a developer that somehow managed to stay away from building applications using AI? Then hop on-board and catch up on all the lingvo!

## Plan

- Run LLM models locally with Ollama
- [Prompt engineering](./01-prompt-engineering/README.md)
- [Get structured outputs](./02-structured-output/README.md)
- [Tools and agents](./03-tools-and-agents/README.md)
- Upcoming: Search local docs/text with a Retrieval-Augmented Generation (RAG) workflow
- Upcoming: Serve and consume AI workflows with Model Context Protocol (MCP)


## Prep

Let's use tools that are local and free. 

1. Install [Ollama](https://ollama.com)
2. Python

This content was tested on a Mac with Apple silicon. I used `bash` terminal, but any console would do. 

## Next 

Jump onto [first course](./00-ollama/README.md)!